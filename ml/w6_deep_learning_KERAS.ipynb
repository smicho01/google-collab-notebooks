{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtACl0GF2SdZ6owcrLA3S1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smicho01/google-collab-notebooks/blob/main/ml/w6_deep_learning_KERAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DEEP LEARNING WITH KERAS"
      ],
      "metadata": {
        "id": "EncJc8vvZhgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multi-layered Perceptron (MLP)"
      ],
      "metadata": {
        "id": "ErulAIFrZm_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init random num. generator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "# split into input and output variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "## Defining model\n",
        "\n",
        "### Set 1st layer input dim to 8 for the 8 input vars.\n",
        "### Dense class define fully connected layers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "8oAyJfP3ZtsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model (note, we didn't leave any testig set ! We trained NN on entire set)\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "TVI1fM9PomqP",
        "outputId": "bb583523-151f-48e8-c5e7-53d4e1035284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7357\n",
            "\n",
            "accuracy: 73.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "eN3012j7o2Cu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Automatic Verification Dataset."
      ],
      "metadata": {
        "id": "bNs0KScWpRwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP with automatic validation set\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)\n"
      ],
      "metadata": {
        "id": "DDT4PSrDpHfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "jKbLhbwTp0UJ",
        "outputId": "1e23bb8e-794c-40b3-e0cd-0c5f2ae35bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7370\n",
            "\n",
            "accuracy: 73.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Manual Verification Dataset"
      ],
      "metadata": {
        "id": "9F09uyTrp1cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP with manual validation set\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# split into 67% for train and 33% for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33,\n",
        "random_state=seed)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)\n"
      ],
      "metadata": {
        "id": "pmYkNKkvp3Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "V0HnV7rop96t",
        "outputId": "a1a55585-831e-47b8-8e70-f15faef718bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6966\n",
            "\n",
            "accuracy: 69.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Manual k-Fold Cross-Validation."
      ],
      "metadata": {
        "id": "DXxR0pJ_rbbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, Y):\n",
        " # create model\n",
        " model = Sequential()\n",
        " model.add(Dense(12, input_dim=8, activation='relu'))\n",
        " model.add(Dense(8, activation='relu'))\n",
        " model.add(Dense(1, activation='sigmoid'))\n",
        " # compile model\n",
        " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " # fit the model\n",
        " model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
        " # evaluate the model\n",
        " scores = model.evaluate(X[test], Y[test], verbose=0)\n",
        " print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        " cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n"
      ],
      "metadata": {
        "id": "Krn8kxnYrdZN",
        "outputId": "78774a0e-a63a-47d3-dcd7-926f02097973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 75.32%\n",
            "accuracy: 76.62%\n",
            "accuracy: 74.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 3934 calls to <function Model.make_test_function.<locals>.test_function at 0x7c35fde0cd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 67.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7c35fde0dbd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 70.13%\n",
            "accuracy: 66.23%\n",
            "accuracy: 72.73%\n",
            "accuracy: 75.32%\n",
            "accuracy: 73.68%\n",
            "accuracy: 80.26%\n",
            "73.19% (+/- 4.02%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Use Keras with Scikit-Learn"
      ],
      "metadata": {
        "id": "NpVG_iuRsc_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}