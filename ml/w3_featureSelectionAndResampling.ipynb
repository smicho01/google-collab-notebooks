{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtFl/5dD0zhPTZ4a+PNUAx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smicho01/google-collab-notebooks/blob/main/ml/w3_featureSelectionAndResampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EHY-sPdD_dP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FEATURE SELECTION AND RESAMPLING (W3)\n",
        "\n"
      ],
      "metadata": {
        "id": "-BTxfQF4_ehd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection"
      ],
      "metadata": {
        "id": "ijDeeWwm_gcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
        "\n",
        "# The code block below uses the chi-squared (ùëê‚Ñéùëñ2) statistical test for non-negative features to select\n",
        "# 4 of the best features from the Pima Indians onset of diabetes dataset.\n",
        "\n",
        "from pandas import read_csv\n",
        "from numpy import set_printoptions\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "# load data\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# feature extraction\n",
        "test  = SelectKBest(score_func=chi2, k=4)\n",
        "fit = test.fit(X, Y)\n",
        "\n",
        "# sumarize scores\n",
        "set_printoptions(precision=3)\n",
        "print(fit.scores_)\n",
        "features = fit.transform(X)\n",
        "\n",
        "# summarize selected features\n",
        "print(features[0:5,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKSXxBbz_nEO",
        "outputId": "4f65c817-bc9c-4901-94fb-9709895c2dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n",
            "[[148.    0.   33.6  50. ]\n",
            " [ 85.    0.   26.6  31. ]\n",
            " [183.    0.   23.3  32. ]\n",
            " [ 89.   94.   28.1  21. ]\n",
            " [137.  168.   43.1  33. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Recursive Feature Elimination"
      ],
      "metadata": {
        "id": "s0JPqsQEOfIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction with RFE\n",
        "\n",
        "# The code block below uses RFE with the logistic regression algorithm to select the top 3 features.\n",
        "# The choice of algorithm does not matter too much as long as it is skillful and consistent.\n",
        "\n",
        "from pandas import read_csv\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# load data\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# feature extraction\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "rfe = RFE(model, )\n",
        "fit = rfe.fit(X, Y)\n",
        "\n",
        "print (\"Num Features: %d\" % fit.n_features_)\n",
        "print (\"Selected Features: %s\" % fit.support_)\n",
        "print (\"Feature Ranking: %s\" % fit.ranking_ )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a8cST6wL7aK",
        "outputId": "cfddc742-26c3-4e4b-a3c9-361ca4cc0087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Features: 4\n",
            "Selected Features: [ True  True False False False  True  True False]\n",
            "Feature Ranking: [1 1 2 4 5 1 1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Reduction using Principal Component Analysis\n",
        "\n",
        "Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a\n",
        "compressed form. Generally this is called a data reduction technique. A property of PCA is that you\n",
        "can choose the number of dimensions or principal components in the transformed result. In the\n",
        "example below, we use PCA and select 3 principal components."
      ],
      "metadata": {
        "id": "tHMOMdoBOnwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction with PCA\n",
        "from pandas import read_csv\n",
        "from sklearn.decomposition import PCA\n",
        "# load data\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# feature extraction\n",
        "pca = PCA(n_components=3)\n",
        "fit = pca.fit(X)\n",
        "# summarize components\n",
        "print (\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
        "print (fit.components_)"
      ],
      "metadata": {
        "id": "tUI59jKYOx_C",
        "outputId": "63ee856e-42ea-4617-cb8f-25b229c9671a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance: [0.88854663 0.06159078 0.02579012]\n",
            "[[-2.02176587e-03  9.78115765e-02  1.60930503e-02  6.07566861e-02\n",
            "   9.93110844e-01  1.40108085e-02  5.37167919e-04 -3.56474430e-03]\n",
            " [-2.26488861e-02 -9.72210040e-01 -1.41909330e-01  5.78614699e-02\n",
            "   9.46266913e-02 -4.69729766e-02 -8.16804621e-04 -1.40168181e-01]\n",
            " [-2.24649003e-02  1.43428710e-01 -9.22467192e-01 -3.07013055e-01\n",
            "   2.09773019e-02 -1.32444542e-01 -6.39983017e-04 -1.25454310e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Importance\n",
        "\n",
        "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance\n",
        "of features. In the example below we construct a ùê∏ùë•ùë°ùëüùëéùëáùëüùëíùëíùë†ùê∂ùëôùëéùë†ùë†ùëñùëìùëñùëíùëü classifier for the Pima\n",
        "Indians onset of diabetes dataset."
      ],
      "metadata": {
        "id": "Y2l-wifqP77u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance with Extra Trees Classifier\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# load data\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# feature extraction\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X, Y)\n",
        "print(model.feature_importances_) #  importance score for each attribute where the larger the score"
      ],
      "metadata": {
        "id": "WgPLWOgwP9YD",
        "outputId": "1094a9a6-0a89-435d-821d-0873aca2e431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.10880883 0.23710398 0.09795178 0.08053766 0.07645399 0.13670099\n",
            " 0.118028   0.14441476]\n"
          ]
        }
      ]
    }
  ]
}